#!/usr/bin/env python3

import os
import sys
import json
from github import Github
from anthropic import Anthropic
import re

class AICodeReviewer:
    def __init__(self):
        self.github_token = os.environ.get('GITHUB_TOKEN')
        self.anthropic_api_key = os.environ.get('ANTHROPIC_API_KEY')
        self.pr_number = int(os.environ.get('PR_NUMBER', 0))
        self.repo_name = os.environ.get('GITHUB_REPOSITORY', '')
        self.changed_files = os.environ.get('CHANGED_FILES', '').split(',')
        
        if not self.github_token or not self.anthropic_api_key:
            print("Error: Missing required API keys")
            sys.exit(1)
        
        self.github = Github(self.github_token)
        self.anthropic = Anthropic(api_key=self.anthropic_api_key)
        self.repo = self.github.get_repo(self.repo_name)
        self.pr = self.repo.get_pull(self.pr_number)
        
        # TDD, Clean Architecture, Refactoring ê´€ë ¨ íŒ¨í„´ë“¤
        self.tdd_patterns = {
            'test_files': [r'.*test.*\.py$', r'.*_test\.js$', r'.*\.test\.ts$', r'.*\.spec\..*$'],
            'test_keywords': ['test_', 'it(', 'describe(', 'context(', '@Test'],
            'assertion_keywords': ['assert', 'expect', 'should', 'verify']
        }
        
        self.clean_architecture_violations = {
            'dependency_inversion': [r'from.*\.infrastructure', r'import.*database', r'new Database'],
            'single_responsibility': [r'class.*Manager.*Controller', r'def.*and.*or.*'],
            'interface_segregation': [r'class.*Interface.*{[\s\S]*?def.*unused'],
            'open_closed': [r'if.*isinstance', r'elif.*type']
        }
        
        self.code_smells = {
            'long_method': 50,  # ë¼ì¸ ìˆ˜ ê¸°ì¤€
            'long_parameter_list': 4,  # ë§¤ê°œë³€ìˆ˜ ìˆ˜ ê¸°ì¤€
            'duplicate_code': [r'(.*\n){3,}\1{3,}'],  # ì¤‘ë³µ ì½”ë“œ íŒ¨í„´
            'large_class': 200,  # í´ë˜ìŠ¤ ë¼ì¸ ìˆ˜ ê¸°ì¤€
            'god_class': [r'class.*{[\s\S]*?(def.*\n){10,}'],
            'feature_envy': [r'\w+\.\w+\.\w+\.\w+'],  # ê¸´ ë©”ì„œë“œ ì²´ì¸
            'data_clumps': [r'def.*\([^)]*,.*[^)]*,.*[^)]*,.*[^)]*\)']
        }
    
    def get_file_diff(self, file_path):
        """PRì—ì„œ íŒŒì¼ì˜ ë³€ê²½ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°"""
        for file in self.pr.get_files():
            if file.filename == file_path:
                return file.patch if file.patch else ""
        return ""
    
    def get_file_content(self, file_path):
        """íŒŒì¼ì˜ ì „ì²´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        try:
            contents = self.repo.get_contents(file_path, ref=self.pr.head.sha)
            return contents.decoded_content.decode('utf-8')
        except:
            return ""
    
    def detect_tdd_violations(self, file_path, content, diff):
        """TDD ìœ„ë°˜ì‚¬í•­ ê²€ì¶œ"""
        violations = []
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ì¸ì§€ í™•ì¸
        is_test_file = any(re.match(pattern, file_path) for pattern in self.tdd_patterns['test_files'])
        
        if not is_test_file:
            # í”„ë¡œë•ì…˜ ì½”ë“œì—ì„œ í…ŒìŠ¤íŠ¸ê°€ ì—†ëŠ” ìƒˆ í•¨ìˆ˜/í´ë˜ìŠ¤ ê²€ì‚¬
            new_functions = re.findall(r'^\+.*(?:def |function |class )', diff, re.MULTILINE)
            if new_functions and not self._has_corresponding_tests(file_path):
                violations.append("ğŸ§ª **TDD ìœ„ë°˜**: ìƒˆë¡œìš´ í•¨ìˆ˜/í´ë˜ìŠ¤ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. Test First ì›ì¹™ì„ ë”°ë¼ í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•´ì£¼ì„¸ìš”.")
        else:
            # í…ŒìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ê²€ì‚¬
            if not any(keyword in content for keyword in self.tdd_patterns['test_keywords']):
                violations.append("ğŸ§ª **TDD êµ¬ì¡°**: í‘œì¤€ í…ŒìŠ¤íŠ¸ êµ¬ì¡°(Given-When-Then ë˜ëŠ” Arrange-Act-Assert)ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
            
            # ì–´ì„œì…˜ ì—†ëŠ” í…ŒìŠ¤íŠ¸ ê²€ì‚¬
            if not any(keyword in content for keyword in self.tdd_patterns['assertion_keywords']):
                violations.append("ğŸ§ª **í…ŒìŠ¤íŠ¸ í’ˆì§ˆ**: í…ŒìŠ¤íŠ¸ì— ëª…ì‹œì ì¸ ì–´ì„œì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ê²€ì¦ êµ¬ë¬¸ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        
        return violations
    
    def detect_clean_architecture_violations(self, content, file_path):
        """í´ë¦° ì•„í‚¤í…ì²˜ ìœ„ë°˜ì‚¬í•­ ê²€ì¶œ"""
        violations = []
        
        # ì˜ì¡´ì„± ì—­ì „ ì›ì¹™ ìœ„ë°˜
        for pattern in self.clean_architecture_violations['dependency_inversion']:
            if re.search(pattern, content, re.IGNORECASE):
                violations.append("ğŸ—ï¸ **ì˜ì¡´ì„± ì—­ì „ ìœ„ë°˜**: ìƒìœ„ ë ˆì´ì–´ê°€ í•˜ìœ„ ë ˆì´ì–´ì— ì§ì ‘ ì˜ì¡´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ì˜ì¡´ì„± ì£¼ì…ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        
        # ë‹¨ì¼ ì±…ì„ ì›ì¹™ ìœ„ë°˜
        class_matches = re.findall(r'class\s+(\w+)', content)
        for class_name in class_matches:
            if any(word in class_name.lower() for word in ['manager', 'controller', 'handler', 'service'] if sum(1 for w in ['manager', 'controller', 'handler', 'service'] if w in class_name.lower()) > 1):
                violations.append(f"ğŸ—ï¸ **ë‹¨ì¼ ì±…ì„ ìœ„ë°˜**: {class_name} í´ë˜ìŠ¤ëª…ì— ì—¬ëŸ¬ ì±…ì„ì´ í˜¼ì¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì—­í• ì„ ë¶„ë¦¬í•´ì£¼ì„¸ìš”.")
        
        # ë ˆì´ì–´ ê²½ê³„ ìœ„ë°˜ ê²€ì‚¬
        if '/domain/' in file_path and ('import.*infrastructure' in content or 'import.*database' in content):
            violations.append("ğŸ—ï¸ **ë ˆì´ì–´ ê²½ê³„ ìœ„ë°˜**: ë„ë©”ì¸ ë ˆì´ì–´ê°€ ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜ ë ˆì´ì–´ì— ì˜ì¡´í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        return violations
    
    def detect_code_smells(self, content, diff):
        """ë§ˆí‹´ íŒŒìš¸ëŸ¬ì˜ ë¦¬íŒ©í„°ë§ ëƒ„ìƒˆ íƒì§€"""
        smells = []
        lines = content.split('\n')
        
        # Long Method ê²€ì‚¬
        methods = re.findall(r'(def\s+\w+.*?(?=\n(?:def|class|$)))', content, re.DOTALL)
        for method in methods:
            if len(method.split('\n')) > self.code_smells['long_method']:
                method_name = re.search(r'def\s+(\w+)', method).group(1)
                smells.append(f"ğŸ”§ **Long Method**: {method_name} ë©”ì„œë“œê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({len(method.split('\n'))}ì¤„). Extract Method ë¦¬íŒ©í„°ë§ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”.")
        
        # Long Parameter List ê²€ì‚¬
        param_matches = re.findall(r'def\s+\w+\(([^)]*)\)', content)
        for params in param_matches:
            param_count = len([p.strip() for p in params.split(',') if p.strip() and p.strip() != 'self'])
            if param_count > self.code_smells['long_parameter_list']:
                smells.append(f"ğŸ”§ **Long Parameter List**: ë§¤ê°œë³€ìˆ˜ê°€ {param_count}ê°œì…ë‹ˆë‹¤. Parameter Object íŒ¨í„´ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        
        # Feature Envy ê²€ì‚¬ (ê¸´ ë©”ì„œë“œ ì²´ì¸)
        if re.search(r'\w+\.\w+\.\w+\.\w+', content):
            smells.append("ğŸ”§ **Feature Envy**: ê¸´ ë©”ì„œë“œ ì²´ì¸ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ë©”í…Œë¥´ ë²•ì¹™ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”.")
        
        # Duplicate Code ê²€ì‚¬ (ê°„ë‹¨í•œ íŒ¨í„´)
        for i, line in enumerate(lines[:-3]):
            if line.strip() and lines[i+1:i+4] == [line] * 3:
                smells.append(f"ğŸ”§ **Duplicate Code**: {i+1}ë²ˆì§¸ ì¤„ ê·¼ì²˜ì— ì¤‘ë³µ ì½”ë“œê°€ ìˆìŠµë‹ˆë‹¤. Extract Methodë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        
        # Large Class ê²€ì‚¬
        class_matches = re.findall(r'(class\s+\w+.*?(?=\nclass|$))', content, re.DOTALL)
        for class_content in class_matches:
            if len(class_content.split('\n')) > self.code_smells['large_class']:
                class_name = re.search(r'class\s+(\w+)', class_content).group(1)
                smells.append(f"ğŸ”§ **Large Class**: {class_name} í´ë˜ìŠ¤ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. Extract Class ë¦¬íŒ©í„°ë§ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”.")
        
        return smells
    
    def _has_corresponding_tests(self, file_path):
        """í•´ë‹¹ íŒŒì¼ì— ëŒ€ì‘í•˜ëŠ” í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸"""
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        test_patterns = [f'test_{base_name}.py', f'{base_name}_test.py', f'{base_name}.test.js']
        
        try:
            for pattern in test_patterns:
                try:
                    self.repo.get_contents(f'tests/{pattern}')
                    return True
                except:
                    try:
                        self.repo.get_contents(f'test/{pattern}')
                        return True
                    except:
                        continue
        except:
            pass
        return False
    
    def analyze_code(self, file_path, diff, content):
        """TDD, í´ë¦° ì•„í‚¤í…ì²˜, ë¦¬íŒ©í„°ë§ ì›ì¹™ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê³ ê¸‰ ì½”ë“œ ë¶„ì„"""
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì–¸ì–´ íŒë³„
        ext = os.path.splitext(file_path)[1]
        language_map = {
            '.py': 'Python',
            '.js': 'JavaScript',
            '.ts': 'TypeScript',
            '.jsx': 'React',
            '.tsx': 'TypeScript React',
            '.java': 'Java',
            '.go': 'Go',
            '.rs': 'Rust',
            '.c': 'C',
            '.cpp': 'C++',
            '.cs': 'C#',
            '.php': 'PHP',
            '.rb': 'Ruby',
            '.swift': 'Swift',
            '.kt': 'Kotlin'
        }
        language = language_map.get(ext, 'Unknown')
        
        # ì „ë¬¸ê°€ ì§€ì‹ ê¸°ë°˜ ê²€ì‚¬ ì‹¤í–‰
        tdd_violations = self.detect_tdd_violations(file_path, content, diff)
        architecture_violations = self.detect_clean_architecture_violations(content, file_path)
        code_smells = self.detect_code_smells(content, diff)
        
        # ì¢…í•©ì ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        expert_insights = "\n".join(tdd_violations + architecture_violations + code_smells)
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì¼„íŠ¸ ë°±ì˜ TDD, ë¡œë²„íŠ¸ ë§ˆí‹´ì˜ í´ë¦° ì•„í‚¤í…ì²˜, ê·¸ë¦¬ê³  ë§ˆí‹´ íŒŒìš¸ëŸ¬ì˜ ë¦¬íŒ©í„°ë§ ì›ì¹™ì— ì •í†µí•œ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…íŠ¸ì…ë‹ˆë‹¤.
        
        ë‹¤ìŒ {language} ì½”ë“œë¥¼ ê²€í† í•˜ê³ , ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        
        ğŸ“ **íŒŒì¼**: {file_path}
        
        ğŸ”„ **ë³€ê²½ì‚¬í•­ (diff)**:
        ```diff
        {diff}
        ```
        
        ğŸ“‹ **ì „ì²´ íŒŒì¼ ë‚´ìš©**:
        ```{language.lower()}
        {content[:4000]}
        ```
        
        ğŸ” **ìë™ ê°ì§€ëœ ì´ìŠˆ**:
        {expert_insights if expert_insights else 'ìë™ ê°ì§€ëœ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.'}
        
        ## ğŸ“Š ë¶„ì„ ì˜ì—­
        
        ### ğŸ§ª TDD (Test-Driven Development) ê´€ì 
        - Red-Green-Refactor ì‚¬ì´í´ ì¤€ìˆ˜ ì—¬ë¶€
        - í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë° í…ŒìŠ¤íŠ¸ í’ˆì§ˆ
        - Test First ì›ì¹™ ì ìš©
        - í…ŒìŠ¤íŠ¸ ì½”ë“œì˜ ê°€ë…ì„± (Given-When-Then)
        - Fast, Independent, Repeatable, Self-validating, Timely ì›ì¹™
        
        ### ğŸ—ï¸ Clean Architecture ê´€ì 
        - SOLID ì›ì¹™ ì¤€ìˆ˜ (íŠ¹íˆ ì˜ì¡´ì„± ì—­ì „)
        - ë ˆì´ì–´ ê°„ ì˜ì¡´ì„± ë°©í–¥
        - ë„ë©”ì¸ ë¡œì§ì˜ ìˆœìˆ˜ì„±
        - ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ì¶”ìƒí™”
        - í”„ë ˆì„ì›Œí¬ ë…ë¦½ì„±
        
        ### ğŸ”§ Refactoring (ì½”ë“œ ëƒ„ìƒˆ) ê´€ì 
        - Long Method, Large Class
        - Duplicate Code, Dead Code
        - Feature Envy, Data Clumps
        - Long Parameter List
        - God Class, Shotgun Surgery
        - Comments (ì½”ë“œë¡œ í‘œí˜„ ê°€ëŠ¥í•œ ê²ƒë“¤)
        
        ### ğŸ›¡ï¸ ì¶”ê°€ í’ˆì§ˆ ê²€ì‚¬
        - ì„±ëŠ¥ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
        - ë³´ì•ˆ ì·¨ì•½ì 
        - ì˜ˆì™¸ ì²˜ë¦¬ ë° ì—ëŸ¬ í•¸ë“¤ë§
        - ë™ì‹œì„± ì•ˆì „ì„±
        
        ## ğŸ“ ì‘ë‹µ í˜•ì‹
        
        ê° ë°œê²¬ëœ ì´ìŠˆì— ëŒ€í•´:
        - ğŸ”´ **[ì‹¬ê°ë„]** ì´ìŠˆ ì œëª©
          - **ê·¼ê±°**: ì–´ë–¤ ì›ì¹™ì„ ìœ„ë°˜í–ˆëŠ”ì§€
          - **ì˜í–¥**: ì½”ë“œì— ë¯¸ì¹˜ëŠ” ë¶€ì •ì  ì˜í–¥
          - **í•´ê²°ì±…**: êµ¬ì²´ì ì¸ ë¦¬íŒ©í„°ë§ ë°©ë²•
          - **ì˜ˆì‹œ ì½”ë“œ**: (í•„ìš”í•œ ê²½ìš°)
        
        ê¸ì •ì ì¸ ë¶€ë¶„:
        - âœ… **ì˜ ì ìš©ëœ ì›ì¹™ë“¤**
        
        ## ğŸ¯ ì¢…í•© í‰ê°€
        - **TDD ì ìˆ˜**: /10
        - **Clean Architecture ì ìˆ˜**: /10  
        - **ì½”ë“œ í’ˆì§ˆ ì ìˆ˜**: /10
        - **ì¢…í•© ì¶”ì²œì‚¬í•­**
        
        ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ í”¼ë“œë°±ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.anthropic.messages.create(
                model="claude-3-opus-20240229",
                max_tokens=3000,
                temperature=0,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return response.content[0].text
        except Exception as e:
            return f"ì½”ë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def parse_review_to_comments(self, review_text, file_path, diff):
        """ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ë¼ì¸ë³„ ì½”ë©˜íŠ¸ë¡œ ë³€í™˜"""
        comments = []
        
        # diffì—ì„œ ë³€ê²½ëœ ë¼ì¸ ë²ˆí˜¸ ì¶”ì¶œ
        diff_lines = diff.split('\n')
        line_mapping = {}
        current_line = 0
        
        for line in diff_lines:
            if line.startswith('@@'):
                # @@ -old_start,old_count +new_start,new_count @@
                match = re.search(r'\+(\d+)', line)
                if match:
                    current_line = int(match.group(1))
            elif line.startswith('+') and not line.startswith('+++'):
                line_mapping[current_line] = line[1:]
                current_line += 1
            elif not line.startswith('-'):
                current_line += 1
        
        # ì‹¬ê°í•œ ì´ìŠˆë“¤ì„ ì°¾ì•„ì„œ ë¼ì¸ ì½”ë©˜íŠ¸ë¡œ ë³€í™˜
        serious_issues = re.findall(r'ğŸ”´.*?(?=ğŸ”´|ğŸ’¡|âœ…|$)', review_text, re.DOTALL)
        
        for issue in serious_issues[:3]:  # ìµœëŒ€ 3ê°œì˜ ì£¼ìš” ì´ìŠˆë§Œ
            # ì½”ë“œ ìŠ¤ë‹ˆí«ì´ë‚˜ íŠ¹ì • íŒ¨í„´ ì°¾ê¸°
            for line_num, line_content in line_mapping.items():
                # ì´ìŠˆê°€ í•´ë‹¹ ë¼ì¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ ê°„ë‹¨íˆ ì²´í¬
                if any(keyword in line_content.lower() for keyword in ['function', 'def', 'class', 'if', 'for', 'while', 'return']):
                    comments.append({
                        'path': file_path,
                        'line': line_num,
                        'body': issue.strip()
                    })
                    break
        
        return comments
    
    def post_review(self):
        """PRì— ë¦¬ë·° ì½”ë©˜íŠ¸ ì‘ì„±"""
        all_reviews = []
        inline_comments = []
        
        # ë³€ê²½ëœ íŒŒì¼ë“¤ ë¶„ì„
        for file_path in self.changed_files:
            if not file_path or file_path.startswith('.'):
                continue
            
            print(f"Analyzing {file_path}...")
            
            diff = self.get_file_diff(file_path)
            content = self.get_file_content(file_path)
            
            if diff:
                review = self.analyze_code(file_path, diff, content)
                all_reviews.append(f"## ğŸ“ {file_path}\n\n{review}")
                
                # ë¼ì¸ë³„ ì½”ë©˜íŠ¸ ìƒì„±
                file_comments = self.parse_review_to_comments(review, file_path, diff)
                inline_comments.extend(file_comments)
        
        # ì „ì²´ ë¦¬ë·° ìš”ì•½ ì‘ì„±
        summary = self.create_summary(all_reviews)
        
        # PRì— ë¦¬ë·° ì½”ë©˜íŠ¸ ì‘ì„±
        try:
            # ì „ì²´ ë¦¬ë·° ì½”ë©˜íŠ¸
            review_body = f"""# ğŸ¤– AI ì½”ë“œ ë¦¬ë·° ê²°ê³¼

{summary}

---

{chr(10).join(all_reviews)}

---

*ì´ ë¦¬ë·°ëŠ” Claude AIì— ì˜í•´ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì œì•ˆì‚¬í•­ì€ ì°¸ê³ ìš©ì´ë©°, ìµœì¢… íŒë‹¨ì€ ê°œë°œìê°€ í•´ì£¼ì„¸ìš”.*
"""
            
            # PR ë¦¬ë·° ìƒì„±
            self.pr.create_review(
                body=review_body,
                event='COMMENT'
            )
            
            # ë¼ì¸ë³„ ì½”ë©˜íŠ¸ ì¶”ê°€ (ê°„ë‹¨í•œ ë°©ë²•)
            for comment in inline_comments[:5]:  # ìµœëŒ€ 5ê°œ ì½”ë©˜íŠ¸
                try:
                    self.pr.create_issue_comment(
                        f"**{comment['path']}** (Line {comment['line']}):\n{comment['body']}"
                    )
                except:
                    pass
            
            print("âœ… ì½”ë“œ ë¦¬ë·°ê°€ ì„±ê³µì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            print(f"âŒ ë¦¬ë·° ì‘ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ì½”ë©˜íŠ¸ëŠ” ë‚¨ê¸°ê¸°
            try:
                self.pr.create_issue_comment(
                    f"ğŸ¤– AI ì½”ë“œ ë¦¬ë·°ë¥¼ ì‹œë„í–ˆìœ¼ë‚˜ ì¼ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: {str(e)}"
                )
            except:
                pass
    
    def create_summary(self, reviews):
        """ì „ì²´ ë¦¬ë·° ìš”ì•½ ìƒì„±"""
        high_priority = len(re.findall(r'ğŸ”´.*?ë†’ìŒ', ''.join(reviews)))
        medium_priority = len(re.findall(r'ğŸ”´.*?ì¤‘ê°„', ''.join(reviews)))
        low_priority = len(re.findall(r'ğŸ”´.*?ë‚®ìŒ', ''.join(reviews)))
        positive = len(re.findall(r'âœ…', ''.join(reviews)))
        
        summary = f"""## ğŸ“Š ë¦¬ë·° ìš”ì•½

- ğŸ”´ **ë†’ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆ**: {high_priority}ê°œ
- ğŸŸ¡ **ì¤‘ê°„ ìš°ì„ ìˆœìœ„ ì´ìŠˆ**: {medium_priority}ê°œ
- ğŸŸ¢ **ë‚®ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆ**: {low_priority}ê°œ
- âœ… **ì˜ ì‘ì„±ëœ ë¶€ë¶„**: {positive}ê°œ

### ğŸ“‹ ê²€í† ëœ íŒŒì¼
{chr(10).join(f"- {f}" for f in self.changed_files if f and not f.startswith('.'))}
"""
        
        if high_priority > 0:
            summary += "\nâš ï¸ **ë†’ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë¨¸ì§€ ì „ ë°˜ë“œì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.**"
        
        return summary

def main():
    try:
        reviewer = AICodeReviewer()
        reviewer.post_review()
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()