#!/usr/bin/env python3

import os
import sys
import json
from github import Github
from anthropic import Anthropic
import re

class AICodeReviewer:
    def __init__(self):
        self.github_token = os.environ.get('GITHUB_TOKEN')
        self.anthropic_api_key = os.environ.get('ANTHROPIC_API_KEY')
        self.pr_number = int(os.environ.get('PR_NUMBER', 0))
        self.repo_name = os.environ.get('GITHUB_REPOSITORY', '')
        self.changed_files = os.environ.get('CHANGED_FILES', '').split(',')
        
        if not self.github_token or not self.anthropic_api_key:
            print("Error: Missing required API keys")
            sys.exit(1)
        
        self.github = Github(self.github_token)
        self.anthropic = Anthropic(api_key=self.anthropic_api_key)
        self.repo = self.github.get_repo(self.repo_name)
        self.pr = self.repo.get_pull(self.pr_number)
        
        # ì¼„íŠ¸ ë°±ì˜ TDD ì›ì¹™ì— ê¸°ë°˜í•œ íŒ¨í„´ë“¤
        self.tdd_patterns = {
            'test_files': [r'.*test.*\.py$', r'.*_test\.js$', r'.*\.test\.ts$', r'.*\.spec\..*$', r'.*Tests?\..*$'],
            'test_keywords': ['test_', 'it(', 'describe(', 'context(', '@Test', 'should', 'when', 'given'],
            'assertion_keywords': ['assert', 'expect', 'should', 'verify', 'toBe', 'toEqual'],
            'red_green_refactor': {
                'red_indicators': ['failing', 'fail', 'error', 'broken'],
                'green_indicators': ['passing', 'pass', 'success'],
                'refactor_indicators': ['refactor', 'cleanup', 'improve']
            },
            'test_structure': {
                'arrange_act_assert': ['arrange', 'act', 'assert', 'given', 'when', 'then'],
                'four_phase_test': ['setup', 'exercise', 'verify', 'teardown']
            }
        }
        
        # ë¡œë²„íŠ¸ ë§ˆí‹´ì˜ í´ë¦° ì•„í‚¤í…ì²˜ì™€ SOLID ì›ì¹™
        self.clean_architecture_violations = {
            'dependency_inversion': {
                'patterns': [r'from.*\.infrastructure', r'import.*database', r'new Database', r'mysql', r'postgresql'],
                'description': 'ìƒìœ„ ëª¨ë“ˆì´ í•˜ìœ„ ëª¨ë“ˆì— ì˜ì¡´í•˜ë©´ ì•ˆë©ë‹ˆë‹¤. ì¶”ìƒí™”ì— ì˜ì¡´í•˜ì„¸ìš”.'
            },
            'single_responsibility': {
                'patterns': [r'class.*Manager.*Controller', r'class.*Service.*Repository', r'def.*and.*or.*'],
                'description': 'í´ë˜ìŠ¤ëŠ” í•˜ë‚˜ì˜ ì±…ì„ë§Œ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.'
            },
            'interface_segregation': {
                'patterns': [r'class.*Interface.*{[\s\S]*?def.*unused'],
                'description': 'í´ë¼ì´ì–¸íŠ¸ëŠ” ìì‹ ì´ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë©”ì„œë“œì— ì˜ì¡´í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.'
            },
            'open_closed': {
                'patterns': [r'if.*isinstance', r'elif.*type', r'switch.*case'],
                'description': 'í™•ì¥ì—ëŠ” ì—´ë ¤ìˆê³  ìˆ˜ì •ì—ëŠ” ë‹«í˜€ìˆì–´ì•¼ í•©ë‹ˆë‹¤.'
            },
            'liskov_substitution': {
                'patterns': [r'raise NotImplementedError', r'pass\s*#.*not.*implemented'],
                'description': 'ì„œë¸Œíƒ€ì…ì€ ê¸°ë°˜íƒ€ì…ì„ ì™„ì „íˆ ëŒ€ì²´í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.'
            },
            'layer_violations': {
                'ui_to_data': [r'from.*\.data', r'import.*repository.*in.*ui'],
                'domain_to_infra': [r'from.*\.infrastructure.*in.*domain'],
                'use_case_to_ui': [r'from.*\.ui.*in.*use.*case']
            }
        }
        
        # ë§ˆí‹´ íŒŒìš¸ëŸ¬ì˜ ë¦¬íŒ©í„°ë§ ì½”ë“œ ìŠ¤ë©œ í™•ì¥
        self.code_smells = {
            'long_method': {'threshold': 20, 'description': 'ë©”ì„œë“œê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. Extract Methodë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.'},
            'long_parameter_list': {'threshold': 3, 'description': 'ë§¤ê°œë³€ìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. Parameter Object íŒ¨í„´ì„ ê³ ë ¤í•˜ì„¸ìš”.'},
            'duplicate_code': {
                'patterns': [r'(.*\n){3,}\1{3,}'],
                'description': 'ì¤‘ë³µ ì½”ë“œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. Extract Method/Classë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.'
            },
            'large_class': {'threshold': 100, 'description': 'í´ë˜ìŠ¤ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. Extract Classë¥¼ ê³ ë ¤í•˜ì„¸ìš”.'},
            'god_class': {
                'patterns': [r'class.*{[\s\S]*?(def.*\n){15,}'],
                'description': 'ì‹  í´ë˜ìŠ¤(God Class)ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì±…ì„ì„ ë¶„ì‚°ì‹œí‚¤ì„¸ìš”.'
            },
            'feature_envy': {
                'patterns': [r'\w+\.\w+\.\w+\.\w+', r'other_object\.[\w\.]+{3,}'],
                'description': 'ë‹¤ë¥¸ ê°ì²´ì˜ ê¸°ëŠ¥ì— ê³¼ë„í•˜ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. Move Methodë¥¼ ê³ ë ¤í•˜ì„¸ìš”.'
            },
            'data_clumps': {
                'patterns': [r'def.*\([^)]*,.*[^)]*,.*[^)]*,.*[^)]*\)'],
                'description': 'ë°ì´í„° ë©ì–´ë¦¬ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. Parameter Objectë¥¼ ë§Œë“œì„¸ìš”.'
            },
            'primitive_obsession': {
                'patterns': [r'def.*\(.*str.*str.*str', r'id_\w+.*:.*int', r'email.*:.*str'],
                'description': 'ì›ì‹œ íƒ€ì… ê°•ë°•ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. Value Objectë¥¼ ë§Œë“œì„¸ìš”.'
            },
            'message_chains': {
                'patterns': [r'\w+\.get\w+\(\)\.get\w+\(\)\.get\w+\(\)'],
                'description': 'ë©”ì‹œì§€ ì²´ì¸ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. Hide Delegateë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.'
            },
            'middle_man': {
                'patterns': [r'def \w+\(.*\):\s*return self\.\w+\.\w+\('],
                'description': 'ì¤‘ê°œì íŒ¨í„´ì´ ê³¼ë„í•©ë‹ˆë‹¤. Remove Middle Manì„ ê³ ë ¤í•˜ì„¸ìš”.'
            },
            'inappropriate_intimacy': {
                'patterns': [r'\._\w+', r'friend\.\w+'],
                'description': 'ë¶€ì ì ˆí•œ ì¹œë°€ë„ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. Move Method/Fieldë¥¼ ê³ ë ¤í•˜ì„¸ìš”.'
            }
        }
    
    def get_file_diff(self, file_path):
        """PRì—ì„œ íŒŒì¼ì˜ ë³€ê²½ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°"""
        for file in self.pr.get_files():
            if file.filename == file_path:
                return file.patch if file.patch else ""
        return ""
    
    def get_file_content(self, file_path):
        """íŒŒì¼ì˜ ì „ì²´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        try:
            contents = self.repo.get_contents(file_path, ref=self.pr.head.sha)
            return contents.decoded_content.decode('utf-8')
        except:
            return ""
    
    def detect_tdd_violations(self, file_path, content, diff):
        """ì¼„íŠ¸ ë°±ì˜ TDD ì›ì¹™ ê¸°ë°˜ ìœ„ë°˜ì‚¬í•­ ê²€ì¶œ - í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ìˆì„ ë•Œë§Œ"""
        violations = []
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ì¸ì§€ í™•ì¸
        is_test_file = any(re.match(pattern, file_path) for pattern in self.tdd_patterns['test_files'])
        
        # í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ í¬í•¨ëœ PRì¸ì§€ í™•ì¸
        has_test_files = any(any(re.match(pattern, f) for pattern in self.tdd_patterns['test_files']) 
                           for f in self.changed_files if f)
        
        # í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ì—†ìœ¼ë©´ TDD ê´€ë ¨ ë¦¬ë·° ìƒëµ
        if not has_test_files:
            return violations
        
        if is_test_file:
            # í…ŒìŠ¤íŠ¸ íŒŒì¼ì—ì„œë§Œ TDD í’ˆì§ˆ ê²€ì‚¬
            # Given-When-Then ë˜ëŠ” Arrange-Act-Assert êµ¬ì¡° ê²€ì‚¬
            has_structure = any(keyword in content.lower() for keyword in self.tdd_patterns['test_structure']['arrange_act_assert'])
            if not has_structure:
                violations.append("ğŸŸ¡ **[ì¤‘ê°„] TDD í…ŒìŠ¤íŠ¸ êµ¬ì¡°**: Given-When-Then ë˜ëŠ” Arrange-Act-Assert êµ¬ì¡°ê°€ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
                                "  - **í•´ê²°ì±…**: í…ŒìŠ¤íŠ¸ë¥¼ ì„¸ ë‹¨ê³„ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ")
            
            # ì–´ì„œì…˜ í’ˆì§ˆ ê²€ì‚¬
            assertions = re.findall(r'(assert\w*|expect\w*|should\w*)', content, re.IGNORECASE)
            if len(assertions) < 1:
                violations.append("ğŸ”´ **[ë†’ìŒ] TDD ê²€ì¦ ë¶€ì¡±**: í…ŒìŠ¤íŠ¸ì— ëª…ì‹œì ì¸ ì–´ì„œì…˜ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                                "  - **ê·¼ê±°**: í…ŒìŠ¤íŠ¸ì˜ í•µì‹¬ì€ ê¸°ëŒ€ê°’ê³¼ ì‹¤ì œê°’ì˜ ë¹„êµ\n"
                                "  - **í•´ê²°ì±…**: ê° í…ŒìŠ¤íŠ¸ë§ˆë‹¤ ìµœì†Œ í•˜ë‚˜ì˜ ëª…í™•í•œ ì–´ì„œì…˜ ì¶”ê°€")
            
            # í…ŒìŠ¤íŠ¸ ë…ë¦½ì„± ê²€ì‚¬
            if 'setUp' in content and 'global' in content:
                violations.append("ğŸŸ¡ **[ì¤‘ê°„] TDD Independent ìœ„ë°˜**: ì „ì—­ ìƒíƒœì— ì˜ì¡´í•˜ëŠ” í…ŒìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤.\n"
                                "  - **í•´ê²°ì±…**: ê° í…ŒìŠ¤íŠ¸ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ê²©ë¦¬")
        
        return violations
    
    def detect_clean_architecture_violations(self, content, file_path):
        """ë¡œë²„íŠ¸ ë§ˆí‹´ì˜ í´ë¦° ì•„í‚¤í…ì²˜ì™€ SOLID ì›ì¹™ ìœ„ë°˜ì‚¬í•­ ê²€ì¶œ"""
        violations = []
        
        # 1. ì˜ì¡´ì„± ì—­ì „ ì›ì¹™(DIP) ìœ„ë°˜
        for pattern in self.clean_architecture_violations['dependency_inversion']['patterns']:
            if re.search(pattern, content, re.IGNORECASE):
                violations.append(f"ğŸ”´ **[ë†’ìŒ] SOLID-DIP ìœ„ë°˜**: {self.clean_architecture_violations['dependency_inversion']['description']}\n"
                                f"  - **ê·¼ê±°**: ë¡œë²„íŠ¸ ë§ˆí‹´ì˜ ì˜ì¡´ì„± ì—­ì „ ì›ì¹™\n"
                                f"  - **ì˜í–¥**: ê²°í•©ë„ ì¦ê°€, í…ŒìŠ¤íŠ¸ ì–´ë ¤ì›€\n"
                                f"  - **í•´ê²°ì±…**: Repository íŒ¨í„´, Dependency Injection ì‚¬ìš©")
        
        # 2. ë‹¨ì¼ ì±…ì„ ì›ì¹™(SRP) ìœ„ë°˜
        for pattern in self.clean_architecture_violations['single_responsibility']['patterns']:
            if re.search(pattern, content, re.IGNORECASE):
                violations.append(f"ğŸŸ¡ **[ì¤‘ê°„] SOLID-SRP ìœ„ë°˜**: {self.clean_architecture_violations['single_responsibility']['description']}\n"
                                f"  - **í•´ê²°ì±…**: Extract Class, Extract Method ì ìš©")
        
        # 3. ë¦¬ìŠ¤ì½”í”„ ì¹˜í™˜ ì›ì¹™(LSP) ìœ„ë°˜
        for pattern in self.clean_architecture_violations['liskov_substitution']['patterns']:
            if re.search(pattern, content, re.IGNORECASE):
                violations.append(f"ğŸŸ¡ **[ì¤‘ê°„] SOLID-LSP ìœ„ë°˜**: {self.clean_architecture_violations['liskov_substitution']['description']}\n"
                                f"  - **í•´ê²°ì±…**: ìƒì†ë³´ë‹¤ ì»´í¬ì§€ì…˜ ì‚¬ìš© ê³ ë ¤")
        
        # 4. ë ˆì´ì–´ ê²½ê³„ ìœ„ë°˜ ê²€ì‚¬ (Clean Architecture)
        if '/domain/' in file_path:
            for pattern in self.clean_architecture_violations['layer_violations']['domain_to_infra']:
                if re.search(pattern, content, re.IGNORECASE):
                    violations.append("ğŸ”´ **[ë†’ìŒ] Clean Architecture ë ˆì´ì–´ ìœ„ë°˜**: ë„ë©”ì¸ì´ ì¸í”„ë¼ì— ì˜ì¡´í•©ë‹ˆë‹¤.\n"
                                    "  - **ê·¼ê±°**: ë‚´ë¶€ ì›ì€ ì™¸ë¶€ ì›ì„ ì•Œì•„ì„œëŠ” ì•ˆë¨\n"
                                    "  - **í•´ê²°ì±…**: í¬íŠ¸ì™€ ì–´ëŒ‘í„° íŒ¨í„´ ì ìš©")
        
        return violations
    
    def detect_code_smells(self, content, diff):
        """ë§ˆí‹´ íŒŒìš¸ëŸ¬ì˜ ë¦¬íŒ©í„°ë§ ëƒ„ìƒˆ íƒì§€"""
        smells = []
        lines = content.split('\n')
        
        # Long Method ê²€ì‚¬
        methods = re.findall(r'(def\s+\w+.*?(?=\n(?:def|class|$)))', content, re.DOTALL)
        for method in methods:
            if len(method.split('\n')) > self.code_smells['long_method']:
                method_name = re.search(r'def\s+(\w+)', method).group(1)
                line_count = len(method.split('\n'))
                smells.append(f"ğŸ”§ **Long Method**: {method_name} ë©”ì„œë“œê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({line_count}ì¤„). Extract Method ë¦¬íŒ©í„°ë§ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”.")
        
        # Long Parameter List ê²€ì‚¬
        param_matches = re.findall(r'def\s+\w+\(([^)]*)\)', content)
        for params in param_matches:
            param_count = len([p.strip() for p in params.split(',') if p.strip() and p.strip() != 'self'])
            if param_count > self.code_smells['long_parameter_list']:
                smells.append(f"ğŸ”§ **Long Parameter List**: ë§¤ê°œë³€ìˆ˜ê°€ {param_count}ê°œì…ë‹ˆë‹¤. Parameter Object íŒ¨í„´ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        
        # Feature Envy ê²€ì‚¬ (ê¸´ ë©”ì„œë“œ ì²´ì¸)
        if re.search(r'\w+\.\w+\.\w+\.\w+', content):
            smells.append("ğŸ”§ **Feature Envy**: ê¸´ ë©”ì„œë“œ ì²´ì¸ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ë©”í…Œë¥´ ë²•ì¹™ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”.")
        
        # Duplicate Code ê²€ì‚¬ (ê°„ë‹¨í•œ íŒ¨í„´)
        for i, line in enumerate(lines[:-3]):
            if line.strip() and lines[i+1:i+4] == [line] * 3:
                smells.append(f"ğŸ”§ **Duplicate Code**: {i+1}ë²ˆì§¸ ì¤„ ê·¼ì²˜ì— ì¤‘ë³µ ì½”ë“œê°€ ìˆìŠµë‹ˆë‹¤. Extract Methodë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        
        # Large Class ê²€ì‚¬
        class_matches = re.findall(r'(class\s+\w+.*?(?=\nclass|$))', content, re.DOTALL)
        for class_content in class_matches:
            if len(class_content.split('\n')) > self.code_smells['large_class']:
                class_name = re.search(r'class\s+(\w+)', class_content).group(1)
                smells.append(f"ğŸ”§ **Large Class**: {class_name} í´ë˜ìŠ¤ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. Extract Class ë¦¬íŒ©í„°ë§ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”.")
        
        return smells
    
    def _has_corresponding_tests(self, file_path):
        """í•´ë‹¹ íŒŒì¼ì— ëŒ€ì‘í•˜ëŠ” í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸"""
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        test_patterns = [f'test_{base_name}.py', f'{base_name}_test.py', f'{base_name}.test.js']
        
        try:
            for pattern in test_patterns:
                try:
                    self.repo.get_contents(f'tests/{pattern}')
                    return True
                except:
                    try:
                        self.repo.get_contents(f'test/{pattern}')
                        return True
                    except:
                        continue
        except:
            pass
        return False
    
    def analyze_code(self, file_path, diff, content):
        """TDD, í´ë¦° ì•„í‚¤í…ì²˜, ë¦¬íŒ©í„°ë§ ì›ì¹™ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê³ ê¸‰ ì½”ë“œ ë¶„ì„"""
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì–¸ì–´ íŒë³„
        ext = os.path.splitext(file_path)[1]
        language_map = {
            '.py': 'Python',
            '.js': 'JavaScript',
            '.ts': 'TypeScript',
            '.jsx': 'React',
            '.tsx': 'TypeScript React',
            '.java': 'Java',
            '.go': 'Go',
            '.rs': 'Rust',
            '.c': 'C',
            '.cpp': 'C++',
            '.cs': 'C#',
            '.php': 'PHP',
            '.rb': 'Ruby',
            '.swift': 'Swift',
            '.kt': 'Kotlin'
        }
        language = language_map.get(ext, 'Unknown')
        
        # ì „ë¬¸ê°€ ì§€ì‹ ê¸°ë°˜ ê²€ì‚¬ ì‹¤í–‰
        tdd_violations = self.detect_tdd_violations(file_path, content, diff)
        architecture_violations = self.detect_clean_architecture_violations(content, file_path)
        code_smells = self.detect_code_smells(content, diff)
        structural_improvements = self.suggest_structural_improvements(content, file_path)
        
        # ì¢…í•©ì ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        expert_insights = "\n".join(tdd_violations + architecture_violations + code_smells + structural_improvements)
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì¼„íŠ¸ ë°±ì˜ TDD, ë¡œë²„íŠ¸ ë§ˆí‹´ì˜ í´ë¦° ì•„í‚¤í…ì²˜, ê·¸ë¦¬ê³  ë§ˆí‹´ íŒŒìš¸ëŸ¬ì˜ ë¦¬íŒ©í„°ë§ ì›ì¹™ì— ì •í†µí•œ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…íŠ¸ì…ë‹ˆë‹¤.
        
        ë‹¤ìŒ {language} ì½”ë“œë¥¼ ê²€í† í•˜ê³ , ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        
        ğŸ“ **íŒŒì¼**: {file_path}
        
        ğŸ”„ **ë³€ê²½ì‚¬í•­ (diff)**:
        ```diff
        {diff}
        ```
        
        ğŸ“‹ **ì „ì²´ íŒŒì¼ ë‚´ìš©**:
        ```{language.lower()}
        {content[:4000]}
        ```
        
        ğŸ” **ìë™ ê°ì§€ëœ ì´ìŠˆ**:
        {expert_insights if expert_insights else 'ìë™ ê°ì§€ëœ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.'}
        
        ## ğŸ“Š ë¶„ì„ ì˜ì—­
        
        ### ğŸ§ª TDD (Test-Driven Development) ê´€ì 
        - Red-Green-Refactor ì‚¬ì´í´ ì¤€ìˆ˜ ì—¬ë¶€
        - í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë° í…ŒìŠ¤íŠ¸ í’ˆì§ˆ
        - Test First ì›ì¹™ ì ìš©
        - í…ŒìŠ¤íŠ¸ ì½”ë“œì˜ ê°€ë…ì„± (Given-When-Then)
        - Fast, Independent, Repeatable, Self-validating, Timely ì›ì¹™
        
        ### ğŸ—ï¸ Clean Architecture ê´€ì 
        - SOLID ì›ì¹™ ì¤€ìˆ˜ (íŠ¹íˆ ì˜ì¡´ì„± ì—­ì „)
        - ë ˆì´ì–´ ê°„ ì˜ì¡´ì„± ë°©í–¥
        - ë„ë©”ì¸ ë¡œì§ì˜ ìˆœìˆ˜ì„±
        - ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ì¶”ìƒí™”
        - í”„ë ˆì„ì›Œí¬ ë…ë¦½ì„±
        
        ### ğŸ”§ Refactoring (ì½”ë“œ ëƒ„ìƒˆ) ê´€ì 
        - Long Method, Large Class
        - Duplicate Code, Dead Code
        - Feature Envy, Data Clumps
        - Long Parameter List
        - God Class, Shotgun Surgery
        - Comments (ì½”ë“œë¡œ í‘œí˜„ ê°€ëŠ¥í•œ ê²ƒë“¤)
        
        ### ğŸ›¡ï¸ ì¶”ê°€ í’ˆì§ˆ ê²€ì‚¬
        - ì„±ëŠ¥ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
        - ë³´ì•ˆ ì·¨ì•½ì 
        - ì˜ˆì™¸ ì²˜ë¦¬ ë° ì—ëŸ¬ í•¸ë“¤ë§
        - ë™ì‹œì„± ì•ˆì „ì„±
        
        ## ğŸ“ ì‘ë‹µ í˜•ì‹
        
        ê° ë°œê²¬ëœ ì´ìŠˆì— ëŒ€í•´:
        - ğŸ”´ **[ì‹¬ê°ë„]** ì´ìŠˆ ì œëª©
          - **ê·¼ê±°**: ì–´ë–¤ ì›ì¹™ì„ ìœ„ë°˜í–ˆëŠ”ì§€
          - **ì˜í–¥**: ì½”ë“œì— ë¯¸ì¹˜ëŠ” ë¶€ì •ì  ì˜í–¥
          - **í•´ê²°ì±…**: êµ¬ì²´ì ì¸ ë¦¬íŒ©í„°ë§ ë°©ë²•
          - **ì˜ˆì‹œ ì½”ë“œ**: (í•„ìš”í•œ ê²½ìš°)
        
        ê¸ì •ì ì¸ ë¶€ë¶„:
        - âœ… **ì˜ ì ìš©ëœ ì›ì¹™ë“¤**
        
        ## ğŸ¯ ì¢…í•© í‰ê°€
        - **TDD ì ìˆ˜**: /10
        - **Clean Architecture ì ìˆ˜**: /10  
        - **ì½”ë“œ í’ˆì§ˆ ì ìˆ˜**: /10
        - **ì¢…í•© ì¶”ì²œì‚¬í•­**
        
        ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ í”¼ë“œë°±ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.anthropic.messages.create(
                model="claude-3-opus-20240229",
                max_tokens=3000,
                temperature=0,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return response.content[0].text
        except Exception as e:
            return f"ì½”ë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def parse_review_to_comments(self, review_text, file_path, diff):
        """ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ë¼ì¸ë³„ ì½”ë©˜íŠ¸ë¡œ ë³€í™˜"""
        comments = []
        
        # diffì—ì„œ ë³€ê²½ëœ ë¼ì¸ ë²ˆí˜¸ ì¶”ì¶œ
        diff_lines = diff.split('\n')
        line_mapping = {}
        current_line = 0
        
        for line in diff_lines:
            if line.startswith('@@'):
                # @@ -old_start,old_count +new_start,new_count @@
                match = re.search(r'\+(\d+)', line)
                if match:
                    current_line = int(match.group(1))
            elif line.startswith('+') and not line.startswith('+++'):
                line_mapping[current_line] = line[1:]
                current_line += 1
            elif not line.startswith('-'):
                current_line += 1
        
        # ì‹¬ê°í•œ ì´ìŠˆë“¤ì„ ì°¾ì•„ì„œ ë¼ì¸ ì½”ë©˜íŠ¸ë¡œ ë³€í™˜
        serious_issues = re.findall(r'ğŸ”´.*?(?=ğŸ”´|ğŸ’¡|âœ…|$)', review_text, re.DOTALL)
        
        for issue in serious_issues[:3]:  # ìµœëŒ€ 3ê°œì˜ ì£¼ìš” ì´ìŠˆë§Œ
            # ì½”ë“œ ìŠ¤ë‹ˆí«ì´ë‚˜ íŠ¹ì • íŒ¨í„´ ì°¾ê¸°
            for line_num, line_content in line_mapping.items():
                # ì´ìŠˆê°€ í•´ë‹¹ ë¼ì¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ ê°„ë‹¨íˆ ì²´í¬
                if any(keyword in line_content.lower() for keyword in ['function', 'def', 'class', 'if', 'for', 'while', 'return']):
                    comments.append({
                        'path': file_path,
                        'line': line_num,
                        'body': issue.strip()
                    })
                    break
        
        return comments
    
    def post_review(self):
        """PRì— ë¦¬ë·° ì½”ë©˜íŠ¸ ì‘ì„±"""
        all_reviews = []
        inline_comments = []
        
        # ë³€ê²½ëœ íŒŒì¼ë“¤ ë¶„ì„
        for file_path in self.changed_files:
            if not file_path or file_path.startswith('.'):
                continue
            
            print(f"Analyzing {file_path}...")
            
            diff = self.get_file_diff(file_path)
            content = self.get_file_content(file_path)
            
            if diff:
                review = self.analyze_code(file_path, diff, content)
                all_reviews.append(f"## ğŸ“ {file_path}\n\n{review}")
                
                # ë¼ì¸ë³„ ì½”ë©˜íŠ¸ ìƒì„±
                file_comments = self.parse_review_to_comments(review, file_path, diff)
                inline_comments.extend(file_comments)
        
        # ì „ì²´ ë¦¬ë·° ìš”ì•½ ì‘ì„±
        summary = self.create_summary(all_reviews)
        
        # PRì— ë¦¬ë·° ì½”ë©˜íŠ¸ ì‘ì„±
        try:
            # ì „ì²´ ë¦¬ë·° ì½”ë©˜íŠ¸
            review_body = f"""# ğŸ¤– AI ì½”ë“œ ë¦¬ë·° ê²°ê³¼

{summary}

---

{chr(10).join(all_reviews)}

---

*ì´ ë¦¬ë·°ëŠ” Claude AIì— ì˜í•´ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì œì•ˆì‚¬í•­ì€ ì°¸ê³ ìš©ì´ë©°, ìµœì¢… íŒë‹¨ì€ ê°œë°œìê°€ í•´ì£¼ì„¸ìš”.*
"""
            
            # PR ë¦¬ë·° ìƒì„±
            self.pr.create_review(
                body=review_body,
                event='COMMENT'
            )
            
            # ë¼ì¸ë³„ ì½”ë©˜íŠ¸ ì¶”ê°€ (ê°„ë‹¨í•œ ë°©ë²•)
            for comment in inline_comments[:5]:  # ìµœëŒ€ 5ê°œ ì½”ë©˜íŠ¸
                try:
                    self.pr.create_issue_comment(
                        f"**{comment['path']}** (Line {comment['line']}):\n{comment['body']}"
                    )
                except:
                    pass
            
            print("âœ… ì½”ë“œ ë¦¬ë·°ê°€ ì„±ê³µì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            print(f"âŒ ë¦¬ë·° ì‘ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ì½”ë©˜íŠ¸ëŠ” ë‚¨ê¸°ê¸°
            try:
                self.pr.create_issue_comment(
                    f"ğŸ¤– AI ì½”ë“œ ë¦¬ë·°ë¥¼ ì‹œë„í–ˆìœ¼ë‚˜ ì¼ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: {str(e)}"
                )
            except:
                pass
    
    def create_summary(self, reviews):
        """ì „ì²´ ë¦¬ë·° ìš”ì•½ ìƒì„±"""
        high_priority = len(re.findall(r'ğŸ”´.*?ë†’ìŒ', ''.join(reviews)))
        medium_priority = len(re.findall(r'ğŸ”´.*?ì¤‘ê°„', ''.join(reviews)))
        low_priority = len(re.findall(r'ğŸ”´.*?ë‚®ìŒ', ''.join(reviews)))
        positive = len(re.findall(r'âœ…', ''.join(reviews)))
        
        summary = f"""## ğŸ“Š ë¦¬ë·° ìš”ì•½

- ğŸ”´ **ë†’ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆ**: {high_priority}ê°œ
- ğŸŸ¡ **ì¤‘ê°„ ìš°ì„ ìˆœìœ„ ì´ìŠˆ**: {medium_priority}ê°œ
- ğŸŸ¢ **ë‚®ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆ**: {low_priority}ê°œ
- âœ… **ì˜ ì‘ì„±ëœ ë¶€ë¶„**: {positive}ê°œ

### ğŸ“‹ ê²€í† ëœ íŒŒì¼
{chr(10).join(f"- {f}" for f in self.changed_files if f and not f.startswith('.'))}
"""
        
        if high_priority > 0:
            summary += "\nâš ï¸ **ë†’ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë¨¸ì§€ ì „ ë°˜ë“œì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.**"
        
        return summary

def main():
    try:
        reviewer = AICodeReviewer()
        reviewer.post_review()
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()